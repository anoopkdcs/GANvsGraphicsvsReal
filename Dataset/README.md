In this study, we utilize a collection of 4000 images generated from ProgressiveGAN [1], StyleGAN [2], StyleGAN2 [3] and StyleGAN2-ADA [4] for the class GAN and 4000 images each from the Computer Graphics versus Photographs dataset [5] for the classes Graphics and Real classes. The details of the dataset can be found in Section IV of the paper. The entire 16000 images used in our study can be found at: 

References
[1] Karras, Tero, Timo Aila, Samuli Laine, and Jaakko Lehtinen. "Progressive growing of gans for improved quality, stability, and variation." arXiv preprint arXiv:1710.10196 (2017).
[2] Karras, Tero, Samuli Laine, and Timo Aila. "A style-based generator architecture for generative adversarial networks." In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 4401-4410. 2019.
[3] Karras, Tero, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. "Analyzing and improving the image quality of stylegan." In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8110-8119. 2020.
[4] Karras, Tero, Miika Aittala, Janne Hellsten, Samuli Laine, Jaakko Lehtinen, and Timo Aila, “Training generative adversarial networks with limited data,” in Proc. NeurIPS, 2020
[5] Tokuda, Eric, Helio Pedrini, and Anderson Rocha. "Computer generated images vs. digital photographs: A synergetic feature and classifier combination approach." Journal of Visual Communication and Image Representation 24, no. 8 (2013): 1276-1292.

