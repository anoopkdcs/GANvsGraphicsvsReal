# Dataset Description 

**1. GAN Graphics Real** </br>
We utilize a collection of 4000 images generated from ProgressiveGAN [1], StyleGAN [2], StyleGAN2 [3] and StyleGAN2-ADA [4] for the class GAN and 4000 images each from the Computer Graphics versus Photographs dataset [5] for the classes Graphics and Real classes. The details of the dataset can be found in Section IV.A of the paper. The entire 16000 images used in our study can be found at: :briefcase: [Download](https://www.google.com)

**2. Generalizability** </br>
Three datasets with 160 images in each class are utilized to conduct the Generalizabilty tests. In the first dataset, images for class GAN is collected from the generated images of PG2 GAN [6] and for Graphics and Real are collected from PRCG and PIM-Google sets of Columbia dataset [7], respectively. Class Real of first dataset is replaced with PIM-Personal set of Columbia dataset to from the second dataset. In the third dataset, images for class GAN is collected from the generated images of Cycle GAN [8], Graphics from Level-Design Reference Database [9] and Real from RAISE [10]. The details of the dataset can be found in Section IV.C.3 of the paper. The entire images used for generalizabilty tests in our study can be found at: :briefcase: [Download](https://www.google.com)

**3. Psychophysics Experiments** </br>
330 images selected from test data of our study. The details of the dataset can be found in Section IV.C.5 of the paper. The entire images used for psychophysics experiments in our study can be found at: :briefcase: [Download](https://www.google.com)

## References
[1] Karras, Tero, Timo Aila, Samuli Laine, and Jaakko Lehtinen. "Progressive growing of gans for improved quality, stability, and variation." arXiv preprint arXiv:1710.10196 (2017). </br>
[2] Karras, Tero, Samuli Laine, and Timo Aila. "A style-based generator architecture for generative adversarial networks." In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 4401-4410. 2019. </br>
[3] Karras, Tero, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. "Analyzing and improving the image quality of stylegan." In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8110-8119. 2020. </br>
[4] Karras, Tero, Miika Aittala, Janne Hellsten, Samuli Laine, Jaakko Lehtinen, and Timo Aila, “Training generative adversarial networks with limited data,” in Proc. NeurIPS, 2020. </br>
[5] Tokuda, Eric, Helio Pedrini, and Anderson Rocha. "Computer generated images vs. digital photographs: A synergetic feature and classifier combination approach." Journal of Visual Communication and Image Representation 24, no. 8 (2013): 1276-1292. </br>
[6] Ma, Liqian, Xu Jia, Qianru Sun, Bernt Schiele, Tinne Tuytelaars, and Luc Van Gool. "Pose guided person image generation." arXiv preprint arXiv:1705.09368 (2017).</br>
[7] Ng, Tian-Tsong, Shih-Fu Chang, Jessie Hsu, and Martin Pepeljugoski. "Columbia photographic images and photorealistic computer graphics dataset." Columbia University, ADVENT Technical Report (2005): 205-2004.</br>
[8] Zhu, Jun-Yan, Taesung Park, Phillip Isola, and Alexei A. Efros. "Unpaired image-to-image translation using cycle-consistent adversarial networks." In Proceedings of the IEEE international conference on computer vision, pp. 2223-2232. 2017.</br>
[9] Piaskiewicz, M. "Level-design reference database." Accessed: Jan 15 (2017): 2018.</br>
[10] Dang-Nguyen, Duc-Tien, Cecilia Pasquini, Valentina Conotter, and Giulia Boato. "Raise: A raw images dataset for digital image forensics." In Proceedings of the 6th ACM multimedia systems conference, pp. 219-224. 2015.
